{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71aaec87",
   "metadata": {},
   "source": [
    "# **Algoritmos de Machine Learning**\n",
    "\n",
    "# **Clasificación**\n",
    "\n",
    "Es el proceso de asignar una etiqueta a un conjunto de datos. Por ejemplo, clasificar correos electrónicos como spam o no spam.\n",
    "\n",
    "# **Algoritmos de Clasificación**\n",
    "\n",
    "- **Regresión Logística**: Utiliza una función logística para modelar la probabilidad de que una instancia pertenezca a una clase.\n",
    "\n",
    "- **Árboles de Decisión**: Utiliza un modelo en forma de árbol para tomar decisiones basadas en las características de los datos.\n",
    "\n",
    "- **Máquinas de Vectores de Soporte (SVM)**: Encuentra un hiperplano que separa las clases de manera óptima en un espacio de alta dimensión.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Tabla de algoritmos de clasificación\n",
    "\n",
    "| Algoritmo                  | Descripción                                                                 |\n",
    "|----------------------------|-----------------------------------------------------------------------------|\n",
    "| Regresión Logística         | Modelo probabilístico que utiliza una función logística para clasificar.   |\n",
    "| Árboles de Decisión         | Modelo en forma de árbol que toma decisiones basadas en características.   |\n",
    "| Máquinas de Vectores de Soporte (SVM) | Encuentra un hiperplano óptimo para separar clases en alta dimensión. |\n",
    "| K-Vecinos Más Cercanos (KNN) | Clasifica basándose en la mayoría de los vecinos más cercanos.          |\n",
    "| Naive Bayes                | Clasificador probabilístico basado en el teorema de Bayes.                 |\n",
    "| Redes Neuronales           | Modelos inspirados en el cerebro humano que aprenden patrones complejos.   |\n",
    "| Gradient Boosting          | Combina múltiples modelos débiles para mejorar la precisión.              |\n",
    "| Random Forest              | Conjunto de árboles de decisión para mejorar la precisión y reducir el sobreajuste. |\n",
    "| LightGBM                   | Algoritmo de boosting eficiente y rápido para grandes conjuntos de datos. |\n",
    "| CatBoost                   | Algoritmo de boosting que maneja bien las variables categóricas.          |\n",
    "| XGBoost                   | Algoritmo de boosting optimizado para velocidad y rendimiento.            |\n",
    "| AdaBoost                   | Combina múltiples clasificadores débiles para formar un clasificador fuerte. |\n",
    "\n",
    "\n",
    "# **Tabla de algoritmos de regresión**\n",
    "\n",
    "| Algoritmo                  | Descripción                                                                 |\n",
    "|----------------------------|-----------------------------------------------------------------------------|\n",
    "| Regresión Lineal            | Modelo lineal que predice una variable continua a partir de variables independientes. |\n",
    "| Regresión Polinómica        | Extensión de la regresión lineal que utiliza polinomios para modelar relaciones no lineales. |\n",
    "| Regresión Ridge             | Regresión lineal con regularización L2 para evitar el sobreajuste.         |\n",
    "| Regresión Lasso             | Regresión lineal con regularización L1 que puede eliminar características irrelevantes. |\n",
    "| Regresión Elastic Net       | Combina las regularizaciones L1 y L2 para mejorar la precisión del modelo. |\n",
    "| Regresión de Árboles de Decisión | Utiliza un modelo en forma de árbol para predecir valores continuos. |\n",
    "| Regresión de Bosques Aleatorios | Conjunto de árboles de decisión para mejorar la precisión y reducir el sobreajuste. |\n",
    "| Regresión de Gradient Boosting | Combina múltiples modelos débiles para mejorar la precisión en la predicción. |\n",
    "| Regresión de XGBoost        | Algoritmo de boosting optimizado para velocidad y rendimiento en regresión. |\n",
    "| Regresión de LightGBM       | Algoritmo de boosting eficiente y rápido para grandes conjuntos de datos en regresión. |\n",
    "| Regresión de CatBoost       | Algoritmo de boosting que maneja bien las variables categóricas en regresión. |\n",
    "| Regresión de Support Vector Machines (SVM) | Utiliza un hiperplano para predecir valores continuos en un espacio de alta dimensión. |\n",
    "| Regresión de K-Vecinos Más Cercanos (KNN) | Predice valores continuos basándose en la media de los vecinos más cercanos. |\n",
    "| Regresión de Redes Neuronales | Modelos inspirados en el cerebro humano que aprenden patrones complejos para la regresión. |\n",
    "\n",
    "# **Tabla de algoritmos de clustering**\n",
    "\n",
    "| Algoritmo                  | Descripción                                                                 |\n",
    "|----------------------------|-----------------------------------------------------------------------------|\n",
    "| K-Means                    | Agrupa datos en K clusters basándose en la distancia a los centroides.    |\n",
    "| DBSCAN                     | Agrupa datos densos y encuentra ruido, no requiere número de clusters.     |\n",
    "| Hierarchical Clustering    | Crea una jerarquía de clusters, puede ser aglomerativo o divisivo.        |\n",
    "| Gaussian Mixture Models (GMM) | Modela datos como una mezcla de distribuciones gaussianas.               |\n",
    "| Mean Shift                 | Encuentra densidades de puntos para identificar clusters.                  |\n",
    "| Spectral Clustering        | Utiliza la teoría espectral para agrupar datos en un espacio de alta dimensión. |\n",
    "| Affinity Propagation       | Agrupa datos basándose en la similitud entre puntos, no requiere número de clusters. |\n",
    "| OPTICS                     | Similar a DBSCAN, pero maneja mejor la variación en la densidad de los clusters. |\n",
    "| Birch                      | Agrupa grandes conjuntos de datos en memoria limitada, construyendo un árbol de clusters. |\n",
    "| Agglomerative Clustering   | Agrupa datos en una jerarquía, fusionando clusters basados en la distancia. |\n",
    "\n",
    "# **Tabla de algoritmos de reducción de dimensionalidad**\n",
    "\n",
    "| Algoritmo                  | Descripción                                                                 |\n",
    "|----------------------------|-----------------------------------------------------------------------------|\n",
    "| PCA (Análisis de Componentes Principales) | Reduce la dimensionalidad proyectando datos en componentes ortogonales. |\n",
    "| t-SNE (t-Distributed Stochastic Neighbor Embedding) | Visualiza datos de alta dimensión en 2D o 3D preservando la estructura local. |\n",
    "| UMAP (Uniform Manifold Approximation and Projection) | Similar a t-SNE, pero más rápido y preserva mejor la estructura global. |\n",
    "| LDA (Análisis Discriminante Lineal) | Reduce la dimensionalidad maximizando la separación entre clases. |\n",
    "| ICA (Análisis de Componentes Independientes) | Descompone señales en componentes independientes, útil en procesamiento de señales. |\n",
    "| Autoencoders               | Redes neuronales que aprenden a codificar y decodificar datos, reduciendo la dimensionalidad. |\n",
    "| Isomap                     | Extensión de MDS que preserva distancias geodésicas en datos no lineales. |\n",
    "| MDS (Escalamiento Multidimensional) | Proyecta datos de alta dimensión en un espacio de menor dimensión preservando distancias. |\n",
    "| Factor Analysis            | Modelo estadístico que reduce la dimensionalidad identificando factores latentes. |\n",
    "| Random Projection         | Proyecta datos de alta dimensión en un espacio de menor dimensión utilizando matrices aleatorias. |\n",
    "\n",
    "\n",
    "# **Tabla de algoritmos de detección de anomalías**\n",
    "\n",
    "| Algoritmo                  | Descripción                                                                 |\n",
    "|----------------------------|-----------------------------------------------------------------------------|\n",
    "| Isolation Forest           | Detecta anomalías aislando puntos en un bosque de árboles de decisión.     |\n",
    "| One-Class SVM             | Utiliza SVM para identificar anomalías en un conjunto de datos.            |\n",
    "| Local Outlier Factor (LOF) | Mide la densidad local de puntos para identificar anomalías.              |\n",
    "| Autoencoders               | Redes neuronales que aprenden a reconstruir datos, detectando anomalías en la reconstrucción. |\n",
    "| Elliptic Envelope          | Modela la distribución de los datos y detecta puntos fuera de la elipse.  |\n",
    "| Statistical Tests         | Utiliza pruebas estadísticas para identificar puntos atípicos en los datos. |\n",
    "| DBSCAN                     | Agrupa datos densos y encuentra ruido, útil para detectar anomalías.      |\n",
    "| K-Means                    | Puede utilizarse para detectar anomalías al identificar puntos lejanos de los centroides. |\n",
    "| Mahalanobis Distance       | Mide la distancia entre un punto y la media de un conjunto de datos, útil para detectar anomalías. |\n",
    "| PCA (Análisis de Componentes Principales) | Puede utilizarse para detectar anomalías al identificar puntos lejanos de los componentes principales. |\n",
    "| Gaussian Mixture Models (GMM) | Modela datos como una mezcla de distribuciones gaussianas, útil para detectar anomalías. |\n",
    "| Robust PCA                | Variante de PCA que es robusta a outliers, útil para detectar anomalías. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caeb826",
   "metadata": {},
   "source": [
    "# **¿Qué es la regresión?**\n",
    "\n",
    "La regresión es una técnica de aprendizaje supervisado utilizada para predecir un valor continuo a partir de variables independientes. El objetivo es encontrar la relación entre las variables y modelar esta relación para hacer predicciones sobre nuevos datos.\n",
    "\n",
    "La regresión se utiliza en una variedad de aplicaciones, como la predicción de precios de viviendas, la estimación de ventas y la modelización de tendencias en datos temporales. Existen diferentes tipos de algoritmos de regresión, cada uno con sus propias características y ventajas.\n",
    "\n",
    "# **¿Qué es la clasificación?**\n",
    "\n",
    "La clasificación es una técnica de aprendizaje supervisado utilizada para asignar etiquetas a instancias de datos. El objetivo es aprender un modelo que pueda predecir la clase o categoría a la que pertenece una nueva instancia basándose en sus características.\n",
    "\n",
    "La clasificación se utiliza en una variedad de aplicaciones, como la detección de spam en correos electrónicos, la identificación de enfermedades a partir de síntomas y la clasificación de imágenes. Existen diferentes tipos de algoritmos de clasificación, cada uno con sus propias características y ventajas.\n",
    "\n",
    "# **¿Qué es el clustering?**\n",
    "\n",
    "El clustering es una técnica de aprendizaje no supervisado utilizada para agrupar instancias de datos en función de sus similitudes. El objetivo es identificar patrones y estructuras en los datos sin necesidad de etiquetas predefinidas.\n",
    "\n",
    "El clustering se utiliza en una variedad de aplicaciones, como la segmentación de clientes, la identificación de grupos en redes sociales y la detección de anomalías. Existen diferentes tipos de algoritmos de clustering, cada uno con sus propias características y ventajas.\n",
    "\n",
    "# **¿Qué es la reducción de dimensionalidad?**\n",
    "\n",
    "La reducción de dimensionalidad es una técnica utilizada para reducir el número de variables en un conjunto de datos, manteniendo la mayor cantidad de información posible. El objetivo es simplificar los datos y facilitar su análisis y visualización.\n",
    "\n",
    "La reducción de dimensionalidad se utiliza en una variedad de aplicaciones, como la visualización de datos, la eliminación de ruido y la mejora del rendimiento de los algoritmos de aprendizaje automático. Existen diferentes tipos de algoritmos de reducción de dimensionalidad, cada uno con sus propias características y ventajas.\n",
    "\n",
    "# **¿Qué es la detección de anomalías?**\n",
    "\n",
    "La detección de anomalías es una técnica utilizada para identificar puntos de datos que se desvían significativamente del comportamiento normal del conjunto de datos. El objetivo es detectar patrones inusuales que pueden indicar problemas o eventos raros.\n",
    "\n",
    "La detección de anomalías se utiliza en una variedad de aplicaciones, como la detección de fraudes, la monitorización de sistemas y la identificación de fallos en maquinaria. Existen diferentes tipos de algoritmos de detección de anomalías, cada uno con sus propias características y ventajas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81aa71",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
